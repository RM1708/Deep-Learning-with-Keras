
runfile('/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py', wdir='/home/rm/Code-DeepLearningWithKeras/Chapter03')
Using TensorFlow backend.
Start Time:  16:32:30.603567
Loading CIFAR10 dataset ...
X_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Converting labels to one-hot  ...
Normalize pixels to [0, 1.0] ...
Sequential construction of network ...
/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`
  model.add(Conv2D(64, 3, 3))
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 7, 7, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 3136)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               1606144   
_________________________________________________________________
activation_5 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_6 (Activation)    (None, 10)                0         
=================================================================
Total params: 1,676,842
Trainable params: 1,676,842
Non-trainable params: 0
_________________________________________________________________
Compiling the model ..
Training ...
Train on 40000 samples, validate on 10000 samples
Epoch 1/40
40000/40000 [==============================] - 748s 19ms/step - loss: 1.8066 - acc: 0.3480 - val_loss: 1.4540 - val_acc: 0.4744
Epoch 2/40
40000/40000 [==============================] - 640s 16ms/step - loss: 1.3460 - acc: 0.5180 - val_loss: 1.2840 - val_acc: 0.5431
Epoch 3/40
40000/40000 [==============================] - 663s 17ms/step - loss: 1.1293 - acc: 0.6023 - val_loss: 0.9475 - val_acc: 0.6606
Epoch 4/40
40000/40000 [==============================] - 695s 17ms/step - loss: 0.9862 - acc: 0.6554 - val_loss: 0.9283 - val_acc: 0.6740
Epoch 5/40
40000/40000 [==============================] - 650s 16ms/step - loss: 0.8879 - acc: 0.6852 - val_loss: 0.8628 - val_acc: 0.6928
Epoch 6/40
40000/40000 [==============================] - 703s 18ms/step - loss: 0.8173 - acc: 0.7142 - val_loss: 0.8867 - val_acc: 0.6865
Epoch 7/40
40000/40000 [==============================] - 698s 17ms/step - loss: 0.7603 - acc: 0.7331 - val_loss: 0.9013 - val_acc: 0.6979
Epoch 8/40
40000/40000 [==============================] - 636s 16ms/step - loss: 0.7131 - acc: 0.7524 - val_loss: 0.7231 - val_acc: 0.7560
Epoch 9/40
40000/40000 [==============================] - 683s 17ms/step - loss: 0.6669 - acc: 0.7683 - val_loss: 0.7123 - val_acc: 0.7513
Epoch 10/40
40000/40000 [==============================] - 635s 16ms/step - loss: 0.6388 - acc: 0.7783 - val_loss: 0.7738 - val_acc: 0.7421
Epoch 11/40
40000/40000 [==============================] - 769s 19ms/step - loss: 0.6128 - acc: 0.7860 - val_loss: 0.6933 - val_acc: 0.7641
Epoch 12/40
40000/40000 [==============================] - 651s 16ms/step - loss: 0.5899 - acc: 0.7964 - val_loss: 0.8030 - val_acc: 0.7252
Epoch 13/40
40000/40000 [==============================] - 710s 18ms/step - loss: 0.5678 - acc: 0.8069 - val_loss: 0.6878 - val_acc: 0.7747
Epoch 14/40
40000/40000 [==============================] - 641s 16ms/step - loss: 0.5517 - acc: 0.8105 - val_loss: 0.7000 - val_acc: 0.7678
Epoch 15/40
40000/40000 [==============================] - 640s 16ms/step - loss: 0.5474 - acc: 0.8126 - val_loss: 0.7037 - val_acc: 0.7670
Epoch 16/40
40000/40000 [==============================] - 706s 18ms/step - loss: 0.5331 - acc: 0.8179 - val_loss: 0.6623 - val_acc: 0.7849
Epoch 17/40
40000/40000 [==============================] - 653s 16ms/step - loss: 0.5346 - acc: 0.8200 - val_loss: 0.7370 - val_acc: 0.7868
Epoch 18/40
40000/40000 [==============================] - 637s 16ms/step - loss: 0.5314 - acc: 0.8199 - val_loss: 0.7692 - val_acc: 0.7544
Epoch 19/40
40000/40000 [==============================] - 661s 17ms/step - loss: 0.5288 - acc: 0.8213 - val_loss: 0.7479 - val_acc: 0.7790
Epoch 20/40
40000/40000 [==============================] - 673s 17ms/step - loss: 0.5265 - acc: 0.8244 - val_loss: 0.7642 - val_acc: 0.7843
Epoch 21/40
40000/40000 [==============================] - 725s 18ms/step - loss: 0.5226 - acc: 0.8265 - val_loss: 0.6380 - val_acc: 0.7924
Epoch 22/40
40000/40000 [==============================] - 670s 17ms/step - loss: 0.5313 - acc: 0.8255 - val_loss: 0.7203 - val_acc: 0.7787
Epoch 23/40
40000/40000 [==============================] - 664s 17ms/step - loss: 0.5267 - acc: 0.8253 - val_loss: 0.7247 - val_acc: 0.7847
Epoch 24/40
40000/40000 [==============================] - 666s 17ms/step - loss: 0.5227 - acc: 0.8289 - val_loss: 0.7858 - val_acc: 0.7847
Epoch 25/40
40000/40000 [==============================] - 662s 17ms/step - loss: 0.5203 - acc: 0.8273 - val_loss: 0.8443 - val_acc: 0.7817
Epoch 26/40
40000/40000 [==============================] - 664s 17ms/step - loss: 0.5320 - acc: 0.8279 - val_loss: 0.7402 - val_acc: 0.7809
Epoch 27/40
40000/40000 [==============================] - 665s 17ms/step - loss: 0.5349 - acc: 0.8267 - val_loss: 0.6542 - val_acc: 0.7882
Epoch 28/40
40000/40000 [==============================] - 661s 17ms/step - loss: 0.5291 - acc: 0.8288 - val_loss: 0.7573 - val_acc: 0.7962
Epoch 29/40
40000/40000 [==============================] - 660s 17ms/step - loss: 0.5322 - acc: 0.8274 - val_loss: 0.6659 - val_acc: 0.7796
Epoch 30/40
40000/40000 [==============================] - 680s 17ms/step - loss: 0.5349 - acc: 0.8270 - val_loss: 0.7947 - val_acc: 0.7797
Epoch 31/40
40000/40000 [==============================] - 631s 16ms/step - loss: 0.5323 - acc: 0.8272 - val_loss: 1.0486 - val_acc: 0.7631
Epoch 32/40
40000/40000 [==============================] - 698s 17ms/step - loss: 0.5363 - acc: 0.8282 - val_loss: 0.8073 - val_acc: 0.7905
Epoch 33/40
40000/40000 [==============================] - 664s 17ms/step - loss: 0.5418 - acc: 0.8245 - val_loss: 0.7649 - val_acc: 0.7640
Epoch 34/40
40000/40000 [==============================] - 651s 16ms/step - loss: 0.5426 - acc: 0.8251 - val_loss: 0.8819 - val_acc: 0.7880
Epoch 35/40
40000/40000 [==============================] - 648s 16ms/step - loss: 0.5394 - acc: 0.8275 - val_loss: 0.9427 - val_acc: 0.7699
Epoch 36/40
40000/40000 [==============================] - 653s 16ms/step - loss: 0.5487 - acc: 0.8256 - val_loss: 0.6727 - val_acc: 0.7862
Epoch 37/40
40000/40000 [==============================] - 617s 15ms/step - loss: 0.5533 - acc: 0.8242 - val_loss: 0.7396 - val_acc: 0.7714
Epoch 38/40
40000/40000 [==============================] - 659s 16ms/step - loss: 0.5594 - acc: 0.8202 - val_loss: 0.7490 - val_acc: 0.7768
Epoch 39/40
40000/40000 [==============================] - 649s 16ms/step - loss: 0.5558 - acc: 0.8217 - val_loss: 0.6902 - val_acc: 0.7891
Epoch 40/40
40000/40000 [==============================] - 650s 16ms/step - loss: 0.5613 - acc: 0.8243 - val_loss: 0.7767 - val_acc: 0.7691
Testing...
10000/10000 [==============================] - 78s 8ms/step

Test score: 0.8118950239181518
Test accuracy: 0.7576
dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])


End Time:  00:00:05.337625

        DONE:  /home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py
        
#################################################################################################

runfile('/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py', wdir='/home/rm/Code-DeepLearningWithKeras/Chapter03')
Using TensorFlow backend.
Start Time:  03:48:02.127688
Loading CIFAR10 dataset ...
X_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
Converting labels to one-hot  ...
Normalize pixels to [0, 1.0] ...
Sequential construction of network ...
/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`
  model.add(Conv2D(64, 3, 3))
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 7, 7, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 3136)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               1606144   
_________________________________________________________________
activation_5 (Activation)    (None, 512)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_6 (Activation)    (None, 10)                0         
=================================================================
Total params: 1,676,842
Trainable params: 1,676,842
Non-trainable params: 0
_________________________________________________________________
Compiling the model ..
Training ...
Define disturbance transformations (shifts/rotates/...) to be applied to input images
Applying defined disturbances ...
/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py:133: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.
  verbose=VERBOSE)
/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py:133: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., verbose=1, steps_per_epoch=390, epochs=40)`
  verbose=VERBOSE)
Epoch 1/40
390/390 [==============================] - 858s 2s/step - loss: 1.7797 - acc: 0.3527
Epoch 2/40
390/390 [==============================] - 772s 2s/step - loss: 1.3888 - acc: 0.5051
Epoch 3/40
390/390 [==============================] - 795s 2s/step - loss: 1.2013 - acc: 0.5716
Epoch 4/40
390/390 [==============================] - 797s 2s/step - loss: 1.0873 - acc: 0.6160
Epoch 5/40
390/390 [==============================] - 793s 2s/step - loss: 1.0109 - acc: 0.6473
Epoch 6/40
390/390 [==============================] - 809s 2s/step - loss: 0.9497 - acc: 0.6669
Epoch 7/40
390/390 [==============================] - 796s 2s/step - loss: 0.9107 - acc: 0.6820
Epoch 8/40
390/390 [==============================] - 795s 2s/step - loss: 0.8778 - acc: 0.6929
Epoch 9/40
390/390 [==============================] - 814s 2s/step - loss: 0.8496 - acc: 0.7060
Epoch 10/40
390/390 [==============================] - 796s 2s/step - loss: 0.8352 - acc: 0.7131
Epoch 11/40
390/390 [==============================] - 793s 2s/step - loss: 0.8185 - acc: 0.7188
Epoch 12/40
390/390 [==============================] - 798s 2s/step - loss: 0.8042 - acc: 0.7257
Epoch 13/40
390/390 [==============================] - 978s 3s/step - loss: 0.7973 - acc: 0.7259
Epoch 14/40
390/390 [==============================] - 867s 2s/step - loss: 0.7855 - acc: 0.7325
Epoch 15/40
390/390 [==============================] - 804s 2s/step - loss: 0.7782 - acc: 0.7345
Epoch 16/40
390/390 [==============================] - 802s 2s/step - loss: 0.7783 - acc: 0.7354
Epoch 17/40
390/390 [==============================] - 800s 2s/step - loss: 0.7709 - acc: 0.7389
Epoch 18/40
390/390 [==============================] - 798s 2s/step - loss: 0.7679 - acc: 0.7391
Epoch 19/40
390/390 [==============================] - 796s 2s/step - loss: 0.7624 - acc: 0.7429
Epoch 20/40
390/390 [==============================] - 797s 2s/step - loss: 0.7686 - acc: 0.7413
Epoch 21/40
390/390 [==============================] - 798s 2s/step - loss: 0.7594 - acc: 0.7426
Epoch 22/40
390/390 [==============================] - 799s 2s/step - loss: 0.7627 - acc: 0.7427
Epoch 23/40
390/390 [==============================] - 763s 2s/step - loss: 0.7603 - acc: 0.7479
Epoch 24/40
390/390 [==============================] - 881s 2s/step - loss: 0.7624 - acc: 0.7443
Epoch 25/40
390/390 [==============================] - 776s 2s/step - loss: 0.7617 - acc: 0.7481
Epoch 26/40
390/390 [==============================] - 777s 2s/step - loss: 0.7658 - acc: 0.7449
Epoch 27/40
390/390 [==============================] - 780s 2s/step - loss: 0.7741 - acc: 0.7453
Epoch 28/40
390/390 [==============================] - 756s 2s/step - loss: 0.7758 - acc: 0.7427
Epoch 29/40
390/390 [==============================] - 780s 2s/step - loss: 0.7726 - acc: 0.7407
Epoch 30/40
390/390 [==============================] - 985s 3s/step - loss: 0.7788 - acc: 0.7418
Epoch 31/40
390/390 [==============================] - 872s 2s/step - loss: 0.7736 - acc: 0.7452
Epoch 32/40
390/390 [==============================] - 958s 2s/step - loss: 0.7891 - acc: 0.7409
Epoch 33/40
390/390 [==============================] - 915s 2s/step - loss: 0.7890 - acc: 0.7418
Epoch 34/40
390/390 [==============================] - 937s 2s/step - loss: 0.7933 - acc: 0.7387
Epoch 35/40
390/390 [==============================] - 788s 2s/step - loss: 0.7884 - acc: 0.7424
Epoch 36/40
390/390 [==============================] - 888s 2s/step - loss: 0.7944 - acc: 0.7383
Epoch 37/40
390/390 [==============================] - 781s 2s/step - loss: 0.7981 - acc: 0.7394
Epoch 38/40
390/390 [==============================] - 819s 2s/step - loss: 0.8080 - acc: 0.7354
Epoch 39/40
390/390 [==============================] - 798s 2s/step - loss: 0.8024 - acc: 0.7375
Epoch 40/40
390/390 [==============================] - 785s 2s/step - loss: 0.8024 - acc: 0.7351
Testing...
10000/10000 [==============================] - 61s 6ms/step

Test score: 0.6406582768440247
Test accuracy: 0.7877
dict_keys(['loss', 'acc'])
Traceback (most recent call last):

  File "<ipython-input-2-17ffa821c927>", line 1, in <module>
    runfile('/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py', wdir='/home/rm/Code-DeepLearningWithKeras/Chapter03')

  File "/home/rm/anaconda3/envs/tensorflow/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py", line 705, in runfile
    execfile(filename, namespace)

  File "/home/rm/anaconda3/envs/tensorflow/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File "/home/rm/Code-DeepLearningWithKeras/Chapter03/2.keras_CIFAR10_V1.py", line 158, in <module>
    plt.plot(history.history['val_acc'])

KeyError: 'val_acc'

